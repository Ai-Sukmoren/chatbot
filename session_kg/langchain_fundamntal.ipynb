{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Langchain application\n",
    "Create a new Python program and copy this code into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain import hub\n",
    "from langchain_community.tools import YouTubeSearchTool\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain.schema.messages import HumanMessage, SystemMessage\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'utilities' to the Python path\n",
    "sys.path.append(r'C:\\Users\\Ai Sukmoren\\Desktop\\chatbot')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from utilities.llms import llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j is a highly scalable, native graph database management system designed to handle complex, interconnected data. Unlike traditional relational databases that use tables and rows, Neo4j uses graph structures with nodes, edges (also called relationships), and properties to represent and store data. This model is particularly well-suited for applications that involve complex queries and relationships, such as social networks, recommendation systems, fraud detection, and network management.\n",
      "\n",
      "Here are some key features of Neo4j:\n",
      "\n",
      "1. **Graph Data Model**: Neo4j uses a property graph model where data is stored as nodes (entities) and relationships (edges) between those nodes. Both nodes and relationships can have properties (key-value pairs).\n",
      "\n",
      "2. **Cypher Query Language**: Neo4j uses Cypher, a powerful and expressive graph query language designed specifically for working with graph data. Cypher queries allow for easy and intuitive traversal of the graph to find patterns and extract information.\n",
      "\n",
      "3. **High Performance**: Neo4j is optimized for graph traversal operations, making it extremely efficient for queries that involve complex relationships and deep data connections.\n",
      "\n",
      "4. **ACID Compliance**: Neo4j ensures data integrity and reliability by adhering to ACID (Atomicity, Consistency, Isolation, Durability) properties.\n",
      "\n",
      "5. **Scalability**: Neo4j offers both horizontal and vertical scaling options. It supports large-scale deployments and can handle billions of nodes and relationships.\n",
      "\n",
      "6. **Strong Ecosystem**: Neo4j has a rich ecosystem including tools for data visualization, ETL (Extract, Transform, Load), and integration with various programming languages and frameworks.\n",
      "\n",
      "7. **Community and Enterprise Editions**: Neo4j is available in both community and enterprise editions. The community edition is open-source, while the enterprise edition includes additional features such as advanced security, monitoring, and clustering.\n",
      "\n",
      "8. **Use Cases**: Neo4j is widely used across various industries for use cases such as social network analysis, recommendation engines, fraud detection, master data management, network and IT operations, and more.\n",
      "\n",
      "Overall, Neo4j provides a robust and flexible platform for working with graph data, enabling organizations to uncover insights and make data-driven decisions based on the interconnected nature of their data.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Neo4j?\"\n",
    "\n",
    "response = (llm.invoke(question)).content\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "        You are a cockney fruit and vegetable seller.\n",
    "        Your role is to assist your customer with their fruit and vegetable needs.\n",
    "        Respond using cockney rhyming slang.\n",
    "\n",
    "        Tell me about the following fruit: {fruit}\n",
    "        Tell me about the following vegetable: {vegatable}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "summary_prompt_template = PromptTemplate(template=template,input_variables=[\"fruit\",\"vegatable\"])\n",
    "\n",
    "\n",
    "\n",
    "response = llm_3.invoke(summary_prompt_template.format(fruit=\"Orange\",vegatable=\"Cucumber\"))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a cockney fruit and vegetable seller.\n",
      "Your role is to assist your customer with their fruit and vegetable needs.\n",
      "Respond using cockney rhyming slang.\n",
      "\n",
      "Tell me about the following fruit: apple\n",
      "Tell me about the following vegatable: cucumber\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Apple, mate? That's a fine bit o' scrumpy! It's the bee's knees, it is. Crunchy and juicy, like a nice bubble and squeak. Perfect for a bit of nosh or even a proper apple pie. Just make sure you don't go up the apples and pears, or you'll end up on your Jack Jones!\n",
      "\n",
      "Now, let me tell ya about this cucumber, me old china. It's a real trouble and strife, it is. All green and firm, like a proper Jack the Ripper. You can have it in a salad or even make a smashing cucumber sandwich. Just don't forget to take the skin off, or you'll be in a right Barney Rubble!\n"
     ]
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\"\"\"\n",
    "You are a cockney fruit and vegetable seller.\n",
    "Your role is to assist your customer with their fruit and vegetable needs.\n",
    "Respond using cockney rhyming slang.\n",
    "\n",
    "Tell me about the following fruit: {fruit}\n",
    "Tell me about the following vegatable: {vegatable}\n",
    "\"\"\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "input_variables = {\"fruit\": \"apple\",\"vegatable\":\"cucumber\"}\n",
    "\n",
    "response = llm_chain.invoke(input_variables)\n",
    "\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(\"\"\"\n",
    "You are a cockney fruit and vegetable seller.\n",
    "Your role is to assist your customer with their fruit and vegetable needs.\n",
    "Respond using cockney rhyming slang.\n",
    "\n",
    "Tell me about the following fruit: {fruit}\n",
    "Tell me about the following vegatable: {vegatable}\n",
    "\"\"\")\n",
    "\n",
    "llm_chain = (\n",
    "    llm=llm,\n",
    "    prompt=template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "input_variables = {\"fruit\": \"apple\",\"vegatable\":\"cucumber\"}\n",
    "\n",
    "response = llm_chain.invoke(input_variables)\n",
    "\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(\"\"\"\n",
    "You are a cockney fruit and vegetable seller.\n",
    "Your role is to assist your customer with their fruit and vegetable needs.\n",
    "Respond using cockney rhyming slang.\n",
    "\n",
    "Tell me about the following fruit: {fruit}\n",
    "\"\"\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template,\n",
    "    output_parser=StrOutputParser()\n",
    ")\n",
    "\n",
    "response = llm_chain.invoke({\"fruit\": \"apple\"})\n",
    "\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(\"\"\"\n",
    "You are a cockney fruit and vegetable seller.\n",
    "Your role is to assist your customer with their fruit and vegetable needs.\n",
    "Respond using cockney rhyming slang.\n",
    "\n",
    "Output JSON as {{\"description\": \"your response here\"}}\n",
    "\n",
    "Tell me about the following fruit: {fruit}\n",
    "\"\"\")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template,\n",
    "    output_parser=SimpleJsonOutputParser()\n",
    ")\n",
    "\n",
    "response = llm_chain.invoke({\"fruit\": \"apple\"})\n",
    "\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chatmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "chat_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chat_chain.invoke({\"question\": \"What is the weather like?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_weather = \"\"\"\n",
    "    {\n",
    "        \"surf\": [\n",
    "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
    "            {\"beach\": \"Polzeath\", \"conditions\": \"Flat and calm\"},\n",
    "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
    "        ]\n",
    "    }\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"context\": current_weather,\n",
    "        \"question\": \"What is the weather like?\"\n",
    "     \n",
    "    }\n",
    ")\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
      "Respond using surfer slang.\n",
      "\n",
      "Chat History: []\n",
      "Context: \n",
      "    {\n",
      "        \"surf\": [\n",
      "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
      "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
      "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
      "        ]\n",
      "    }\n",
      "Question: hi\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hey there, bro! Stoked to chat about the gnarly waves! What's the surf sitch you're curious about? 🤙\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
      "Respond using surfer slang.\n",
      "\n",
      "Chat History: [HumanMessage(content='hi'), AIMessage(content=\"Hey there, bro! Stoked to chat about the gnarly waves! What's the surf sitch you're curious about? 🤙\")]\n",
      "Context: \n",
      "    {\n",
      "        \"surf\": [\n",
      "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
      "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
      "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
      "        ]\n",
      "    }\n",
      "Question: can you teach me surf\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hey dude, for sure! First thing, you gotta respect the ocean, it's all about the vibe and feeling the rhythm of the waves. Start with the basics, like paddling out and popping up on your board. It's crucial to get your balance dialed in and learn how to read the waves.\n",
      "\n",
      "At Fistral, you'd have a rad time with those 6ft waves and offshore winds. It's primo conditions for carving up the face and getting tubed if you've got the skills. But if you're just starting out, maybe look for something a little more mellow, like 2-3ft rollers.\n",
      "\n",
      "Bells being flat and calm is a no-go for surfing, but it's perfect for a chill day, maybe work on your pop-up technique on the sand. Watergate Bay with those 3ft waves and onshore winds - it's a bit choppy, but still righteous for learning, just stick close to the whitewater until you get the hang of it.\n",
      "\n",
      "Remember, it's all about having fun and going with the flow. Never drop in on another surfer's wave, that's like, totally not cool. And always keep an eye out for the sets. Grab a soft-top board to start, they're more forgiving. Paddle out, wait for a nice one, and when it feels right, paddle hard, pop up, and ride that wave to the beach, dude!\n",
      "\n",
      "Keep practicing, and before you know it, you'll be shredding like a pro. Stay stoked! 🤙\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\n",
    "Chat History: {chat_history}\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\",\n",
    "    input_variables=[\"chat_history\", \"context\", \"question\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", input_key=\"question\", return_messages=True\n",
    ")\n",
    "\n",
    "chat_chain = LLMChain(llm=llm, prompt=prompt, memory=memory, verbose=True)\n",
    "\n",
    "current_weather = \"\"\"\n",
    "    {\n",
    "        \"surf\": [\n",
    "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
    "            {\"beach\": \"Bells\", \"conditions\": \"Flat and calm\"},\n",
    "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
    "        ]\n",
    "    }\"\"\"\n",
    "    \n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    if question == 'exit':\n",
    "        break\n",
    "    else:\n",
    "        response = chat_chain.invoke({\"context\": current_weather, \"question\": question})\n",
    "        print(response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: Hello! How can I assist you today?\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'hi', 'chat_history': [HumanMessage(content='hi'), AIMessage(content='Hello! How can I assist you today?\\n```')], 'output': 'Hello! How can I assist you today?\\n```'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```\n",
      "Thought: Do I need to use a tool? No\n",
      "Final Answer: Determining the \"best\" horror movie of 2018 can be subjective as it depends on individual tastes and criteria for what makes a horror movie great. However, one film that received critical acclaim and was popular among audiences is \"Hereditary\" directed by Ari Aster. It's known for its intense atmosphere, strong performances, particularly by Toni Collette, and its chilling and unsettling narrative. Other notable horror films from 2018 include \"A Quiet Place\" by John Krasinski and \"Halloween\" which is a sequel to the original 1978 film. Each of these films has its own unique approach to horror and may be considered the best depending on who you ask.\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'what is the best horror movie of 2018', 'chat_history': [HumanMessage(content='hi'), AIMessage(content='Hello! How can I assist you today?\\n```'), HumanMessage(content='what is the best horror movie of 2018'), AIMessage(content='Determining the \"best\" horror movie of 2018 can be subjective as it depends on individual tastes and criteria for what makes a horror movie great. However, one film that received critical acclaim and was popular among audiences is \"Hereditary\" directed by Ari Aster. It\\'s known for its intense atmosphere, strong performances, particularly by Toni Collette, and its chilling and unsettling narrative. Other notable horror films from 2018 include \"A Quiet Place\" by John Krasinski and \"Halloween\" which is a sequel to the original 1978 film. Each of these films has its own unique approach to horror and may be considered the best depending on who you ask.\\n```')], 'output': 'Determining the \"best\" horror movie of 2018 can be subjective as it depends on individual tastes and criteria for what makes a horror movie great. However, one film that received critical acclaim and was popular among audiences is \"Hereditary\" directed by Ari Aster. It\\'s known for its intense atmosphere, strong performances, particularly by Toni Collette, and its chilling and unsettling narrative. Other notable horror films from 2018 include \"A Quiet Place\" by John Krasinski and \"Halloween\" which is a sequel to the original 1978 film. Each of these films has its own unique approach to horror and may be considered the best depending on who you ask.\\n```'}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a movie expert. You find movies from a genre or plot.\n",
    "\n",
    "    ChatHistory:{chat_history}\n",
    "    Question:{input}\n",
    "    \"\"\",\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "\n",
    "youtube = YouTubeSearchTool()\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        name=\"Movie Chat\",\n",
    "        description=\"For when you need to chat about movies. The question will be a string. Return a string.\",\n",
    "        func=chain.run,\n",
    "        return_direct=True\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        name=\"Movie Trailer Search\",\n",
    "        description=\"Use when needing to find a movie trailer. The question will include the word 'trailer'. Return a link to a YouTube video.\",\n",
    "        func=youtube.run,\n",
    "        return_direct=True\n",
    "    )\n",
    "]\n",
    "agent_prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "agent = create_react_agent(llm, tools, agent_prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    max_interations=3,\n",
    "    verbose=True,\n",
    "    handle_parse_errors=True\n",
    "    )\n",
    "\n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    if question == 'exit':\n",
    "        break\n",
    "    else:\n",
    "        response = agent_executor.invoke({\"input\": question})\n",
    "        print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
