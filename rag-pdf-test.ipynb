{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from typing_extensions import Concatenate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the environment variables\n",
    "api_key = os.getenv('api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model='gpt-4o', \n",
    ")\n",
    "\n",
    "embedding = OpenAIEmbeddings(\n",
    "    api_key=api_key,\n",
    "    model='text-embedding-3-small'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PdfReader(r'C:\\Users\\Ai Sukmoren\\Desktop\\kmitl-chatbot\\temp\\The Impact of Discrimination in the Workplace-DESKTOP-UB36V5M.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_4008e3b719', 'finish_reason': 'stop', 'logprobs': None}, id='run-86710721-11ba-4167-af41-b9e24dc81d3e-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdf.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_search = FAISS.from_texts(texts, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The paper was made by Ai Sukmoren (61100447), Kittapat Lochindarat (61100466), and Nattapat Chotirawi (61100480).'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Who made this paper\"\n",
    "docs = document_search.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_to_faiss_search(pdf_path, embedding_model):\n",
    "    # Read the PDF file\n",
    "    pdf = PdfReader(pdf_path)\n",
    "    \n",
    "    # Extract text from the PDF\n",
    "    raw_text = ''\n",
    "    for page in pdf.pages:\n",
    "        content = page.extract_text()\n",
    "        if content:\n",
    "            raw_text += content\n",
    "    \n",
    "    # Split the text using Character Text Splitter\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    texts = text_splitter.split_text(raw_text)\n",
    "    \n",
    "    # Create FAISS document search\n",
    "    document_search = FAISS.from_texts(texts, embedding_model)\n",
    "    \n",
    "    # Save the FAISS index locally\n",
    "    document_search.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Load the FAISS index with allow_dangerous_deserialization set to True\n",
    "index_path = r\"C:\\Users\\(Ai)AiSukmoren\\Desktop\\KMITL-present\\faiss_index\"\n",
    "document_search = FAISS.load_local(index_path, embedding, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Define your query\n",
    "query = \"what the section olar Energy Offerings says\"\n",
    "\n",
    "# Perform a similarity search\n",
    "docs = document_search.similarity_search(query)\n",
    "\n",
    "# Load a QA chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "# Run the QA chain\n",
    "answer = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "print(\"Answer:\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_rag_answer(query:str)->str:\n",
    "    # Load the FAISS index with allow_dangerous_deserialization set to True\n",
    "    index_path = r\"C:\\Users\\(Ai)AiSukmoren\\Desktop\\KMITL-present\\faiss_index\"\n",
    "    document_search = FAISS.load_local(index_path, embedding, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    # Perform a similarity search\n",
    "    docs = document_search.similarity_search(query)\n",
    "\n",
    "    # Load a QA chain\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "    # Run the QA chain\n",
    "    answer = chain.run(input_documents=docs, question=query)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = gen_rag_answer('what the section olar Energy Offerings says')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
